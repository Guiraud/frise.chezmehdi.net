# Guide de D√©marrage Rapide - G√©n√©rateur de Frises Chronologiques

Ce guide explique comment d√©marrer rapidement avec le g√©n√©rateur de frises chronologiques selon votre environnement de d√©veloppement.

## üéØ Aper√ßu rapide

Le syst√®me g√©n√®re automatiquement des composants Vue.js de frises chronologiques en utilisant :
- **MCP-Delegate** pour la distribution sur plusieurs LLMs
- **Pens√©e s√©quentielle** pour l'analyse intelligente des besoins  
- **Templates sp√©cialis√©s** pour diff√©rents domaines

---

## üñ•Ô∏è Cursor IDE

### Installation rapide

1. **Ouvrir le projet dans Cursor**
   ```bash
   cursor /Users/mguiraud/Documents/gitlab/frise.chezmehdi.net
   ```

2. **Naviguer vers le g√©n√©rateur**
   ```bash
   cd generators
   npm install
   ```

3. **Configuration Cursor pour MCP**
   - Ouvrir les param√®tres Cursor (`Cmd+,`)
   - Aller dans "Extensions" > "MCP"
   - Ajouter la configuration :
   ```json
   {
     "mcpServers": {
       "timeline-generator": {
         "command": "node",
         "args": ["main.js"],
         "cwd": "./generators"
       }
     }
   }
   ```

### Utilisation dans Cursor

1. **Chat avec le g√©n√©rateur**
   - Ouvrir le chat Cursor (`Cmd+L`)
   - Taper : `@mcp timeline-generator generate config/historical.json`

2. **G√©n√©ration interactive**
   ```
   @mcp G√©n√®re une frise chronologique pour l'histoire de l'informatique
   Type: historical
   Domaine: computer_science  
   P√©riode: 1940-2024
   Public: √©tudiants
   ```

3. **Analyse de code existant**
   - S√©lectionner un composant Vue existant
   - Chat : `@mcp Analyse ce composant et propose des optimisations avec le g√©n√©rateur`

### Int√©gration Cursor Composer

```typescript
// .cursor/composer.json
{
  "tools": {
    "timeline-generator": {
      "command": "./generators/main.js",
      "description": "G√©n√®re des frises chronologiques avec IA",
      "examples": [
        "generate config/scientific.json",
        "analyze '{\"type\":\"business\"}'"
      ]
    }
  }
}
```

---

## üåä Windsurf IDE

### Configuration Windsurf

1. **Installer l'extension MCP**
   - Ouvrir Windsurf
   - Extensions > Chercher "MCP"
   - Installer "MCP Client for Windsurf"

2. **Configuration des outils**
   ```json
   // .windsurf/tools.json
   {
     "timeline_generator": {
       "type": "command",
       "command": "node generators/main.js",
       "description": "G√©n√©rateur de frises chronologiques IA",
       "parameters": {
         "action": {
           "type": "string",
           "enum": ["generate", "analyze", "test", "fragment"]
         },
         "config": {
           "type": "string",
           "description": "Configuration JSON ou chemin vers fichier"
         }
       }
     }
   }
   ```

### Utilisation Windsurf

1. **Commande rapide**
   - `Ctrl+Shift+P` > "Windsurf: Run Tool"
   - S√©lectionner "timeline_generator"
   - Action: "generate"
   - Config: "config/historical.json"

2. **Flow interactif**
   ```
   ü§ñ Windsurf AI: Je vais g√©n√©rer une frise chronologique pour vous.
   
   1. Quel type souhaitez-vous ?
      - Historique üìö
      - Scientifique üî¨  
      - Business üíº
      - Personnel üë§
      - Projet üöÄ
   
   2. [Utilisateur] Scientifique pour la physique quantique
   
   3. üîÑ Ex√©cution: timeline_generator --action=analyze --config='{"type":"scientific","domain":"quantum_physics"}'
   ```

3. **Int√©gration avec Cascade**
   ```yaml
   # .windsurf/cascade.yml
   flows:
     timeline_creation:
       steps:
         - tool: timeline_generator
           action: analyze
           input: user_requirements
         - tool: timeline_generator  
           action: generate
           input: analysis_result
         - action: open_file
           file: src/generated/*.vue
   ```

### Windsurf Copilot Integration

```javascript
// .windsurf/copilot-config.js
module.exports = {
  tools: {
    timelineGen: {
      trigger: '//timeline',
      action: async (context) => {
        const { exec } = require('child_process');
        const prompt = context.selection || context.prompt;
        
        return new Promise((resolve) => {
          exec(`node generators/main.js analyze '${prompt}'`, (error, stdout) => {
            resolve(stdout);
          });
        });
      }
    }
  }
};
```

---

## üñ•Ô∏è Claude Desktop

### Configuration MCP pour Claude Desktop

1. **Fichier de configuration**
   ```json
   // ~/claude_desktop_config.json (macOS)
   // %APPDATA%\Claude\claude_desktop_config.json (Windows)
   {
     "mcpServers": {
       "timeline-generator": {
         "command": "node",
         "args": ["/Users/mguiraud/Documents/gitlab/frise.chezmehdi.net/generators/main.js"],
         "env": {
           "NODE_ENV": "production"
         }
       },
       "timeline-delegator": {
         "command": "node", 
         "args": ["/Users/mguiraud/Documents/gitlab/frise.chezmehdi.net/generators/mcp-demo.js"],
         "env": {
           "MCP_DELEGATE": "true"
         }
       }
     }
   }
   ```

### Utilisation avec Claude Desktop

1. **G√©n√©ration simple**
   ```
   Utilisateur: Peux-tu g√©n√©rer une frise chronologique pour l'histoire de l'art ?

   Claude: Je vais utiliser le g√©n√©rateur de frises chronologiques pour cr√©er un composant sp√©cialis√©.

   [Appel MCP: timeline-generator generate]
   Configuration: type=historical, domain=art_history, features=[image_gallery, artist_details]

   ‚úÖ Composant TimelineArtHistory.vue g√©n√©r√© avec succ√®s !
   ```

2. **Analyse avanc√©e avec pens√©e s√©quentielle**
   ```
   Utilisateur: J'ai besoin d'optimiser ma frise existante qui rame avec 2000 √©v√©nements

   Claude: Je vais analyser vos besoins avec le moteur de pens√©e s√©quentielle.

   [Appel MCP: timeline-generator analyze]
   Analyse en 8 √©tapes...
   
   Recommandations:
   - Virtualisation pour gros datasets
   - Clustering intelligent
   - Lazy loading optimis√©
   ```

3. **Fragmentation de prompts complexes**
   ```
   Utilisateur: [Prompt tr√®s complexe de 3000 caract√®res sur une timeline collaborative multi-utilisateurs]

   Claude: Ce prompt est complexe, je vais le fragmenter intelligemment.

   [Appel MCP: timeline-delegator fragment]
   üìë Fragment√© en 4 parties
   ü§ñ Distribution: llama3.2, mistral, codellama
   ‚úÖ Analyse fusionn√©e et coh√©rente
   ```

### Commandes Claude Desktop sp√©cialis√©es

```
üéØ Commandes rapides pour Claude Desktop:

"G√©n√®re timeline historique" 
‚Üí G√©n√©ration automatique avec config par d√©faut

"Analyse besoins: [description]"
‚Üí Analyse s√©quentielle des besoins

"Optimise timeline existante"  
‚Üí Analyse et recommandations d'optimisation

"Test connectivit√© LLM"
‚Üí V√©rification des mod√®les disponibles

"Fragmente: [prompt complexe]"
‚Üí D√©composition intelligente multi-LLM
```

---

## üöÄ D√©marrage rapide universel

### En 3 minutes chrono

```bash
# 1. Clone et setup (30s)
cd /Users/mguiraud/Documents/gitlab/frise.chezmehdi.net/generators
npm install

# 2. Test rapide (60s)  
./launch.sh check

# 3. Premi√®re g√©n√©ration (90s)
node main.js generate config/historical.json
```

### V√©rification du succ√®s

‚úÖ **Composant g√©n√©r√©** : `src/generated/TimelineXXX.vue`  
‚úÖ **Documentation** : `src/generated/TimelineXXX.md`  
‚úÖ **Logs positifs** : Pas d'erreur dans la console  
‚úÖ **MCP connect√©** : LLMs d√©tect√©s dans les tests  

---

## üõ†Ô∏è Configuration par IDE

### Variables d'environnement communes

```bash
# .env (pour tous les IDEs)
NODE_ENV=development
MCP_ENDPOINT=http://localhost:11434
MCP_MODELS=llama3.2,mistral,codellama
TIMELINE_OUTPUT_DIR=../src/generated
THINKING_ENGINE_ENABLED=true
```

### Scripts package.json

```json
{
  "scripts": {
    "gen": "node main.js generate",
    "analyze": "node main.js analyze", 
    "test-mcp": "node main.js test",
    "demo": "./launch.sh demo",
    "cursor:setup": "node setup-cursor.js",
    "windsurf:setup": "node setup-windsurf.js", 
    "claude:setup": "node setup-claude.js"
  }
}
```

---

## üîß D√©pannage rapide

### Probl√®mes courants

**‚ùå "MCP Server not found"**
```bash
# V√©rifier le chemin absolu
which node
pwd
# Mettre √† jour la config avec les bons chemins
```

**‚ùå "Ollama connection failed"** 
```bash
# D√©marrer Ollama
ollama serve
# Installer les mod√®les
ollama pull llama3.2
```

**‚ùå "Template generation failed"**
```bash
# V√©rifier les permissions
chmod +x launch.sh
# Recr√©er les templates
./launch.sh clean && ./launch.sh demo
```

### Tests de validation

```bash
# Test complet (2 minutes)
./launch.sh check

# Test MCP uniquement
node main.js test

# Test g√©n√©ration basique
node main.js generate '{"type":"historical","name":"Test"}'
```

---

## üìö Ressources et liens

### Documentation
- [Guide complet](README.md) - Documentation d√©taill√©e
- [Int√©gration](INTEGRATION.md) - Int√©gration dans le projet principal
- [Configs d'exemple](config/) - Templates de configuration

### Support MCP
- [MCP Specification](https://spec.modelcontextprotocol.io/)
- [Ollama Setup](https://ollama.ai/download)
- [Claude Desktop](https://claude.ai/download)

### Communaut√©
- **Issues** : GitLab Issues du projet
- **Discussions** : Channels MCP communautaires
- **Updates** : Suivre les mises √† jour du projet

---

## üéâ Pr√™t √† commencer !

Choisissez votre IDE et suivez la section correspondante. En quelques minutes, vous aurez un syst√®me complet de g√©n√©ration automatique de frises chronologiques avec IA ! 

Pour toute question : consultez d'abord le [README.md](README.md) puis ouvrez une issue si n√©cessaire.

**Happy coding! üöÄ**
